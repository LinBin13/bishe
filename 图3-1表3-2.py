# -*- coding: utf-8 -*-
"""
åæŠ˜äº¤å‰éªŒè¯å‰ªææ•ˆæœåˆ†æï¼ˆä¿®å¤ç‰ˆï¼‰
è§£å†³cross_val_scoreä¸æ”¯æŒreturn_train_scoreçš„é—®é¢˜
ä¾èµ–: pandas==2.1.0, scikit-learn==1.3.0, matplotlib==3.8.0
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold, cross_validate
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import make_scorer, accuracy_score

# è§£å†³ä¸­æ–‡ä¹±ç 
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†ï¼ˆå«é”™è¯¯å¤„ç†ï¼‰
try:
    df = pd.read_csv('student-por.csv', sep=';')
except FileNotFoundError:
    print("âŒ é”™è¯¯ï¼šè¯·å°†student-por.csvæ”¾åœ¨å½“å‰ç›®å½•")
    print("ğŸ“Œ ä¸‹è½½åœ°å€ï¼šhttps://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip")
    exit()

# æ•°æ®æ¸…æ´—ä¸ç‰¹å¾å·¥ç¨‹
df['G3_class'] = (df['G3'] >= 10).astype(int)  # åŠæ ¼çº¿10åˆ†
selected_features = ['failures', 'studytime', 'absences', 'age', 'Walc', 'famrel']  # TOP6ç‰¹å¾
df = df[selected_features + ['G3_class']].dropna()  # ç§»é™¤ç¼ºå¤±å€¼
if len(df) < 10:  # ç¡®ä¿åæŠ˜éªŒè¯æœ‰è¶³å¤Ÿæ ·æœ¬
    print("âŒ é”™è¯¯ï¼šæ¸…æ´—åæ ·æœ¬æ•°ä¸è¶³10ï¼Œæ— æ³•è¿›è¡ŒåæŠ˜éªŒè¯")
    exit()

X, y = df[selected_features], df['G3_class']

# 2. åæŠ˜åˆ†å±‚äº¤å‰éªŒè¯ï¼ˆä¿®å¤ç‰ˆæ ¸å¿ƒï¼‰
depths = range(1, 11)  # æµ‹è¯•æ·±åº¦1-10
cv_results = []
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)  # åˆ†å±‚æŠ½æ ·ä¿æŒç±»åˆ«åˆ†å¸ƒ

for depth in depths:
    model = DecisionTreeClassifier(
        max_depth=depth,
        min_samples_leaf=10,
        random_state=42
    )

    # ä½¿ç”¨cross_validateæ›¿ä»£cross_val_scoreï¼ˆä¿®å¤TypeErrorï¼‰
    cv = cross_validate(
        estimator=model,
        X=X,
        y=y,
        cv=skf,
        scoring=make_scorer(accuracy_score),
        n_jobs=-1,  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒåŠ é€Ÿ
        return_train_score=False  # ä»…éœ€è¦æµ‹è¯•é›†åˆ†æ•°
    )

    # è®­ç»ƒå…¨é‡æ•°æ®è·å–å¶èŠ‚ç‚¹æ•°ï¼ˆä»£è¡¨æ ‘å¤æ‚åº¦ï¼‰
    full_model = model.fit(X, y)
    cv_results.append({
        'depth': depth,
        'leaves': full_model.get_n_leaves(),  # å¶èŠ‚ç‚¹æ•°
        'mean_acc': cv['test_score'].mean(),  # åæŠ˜å¹³å‡å‡†ç¡®ç‡
        'std_acc': cv['test_score'].std(),  # å‡†ç¡®ç‡æ ‡å‡†å·®
        'min_acc': cv['test_score'].min(),  # æœ€ä½å•æŠ˜å‡†ç¡®ç‡
        'max_acc': cv['test_score'].max()  # æœ€é«˜å•æŠ˜å‡†ç¡®ç‡
    })

# 3. ç»“æœåˆ†æ
cv_df = pd.DataFrame(cv_results)
best_idx = cv_df['mean_acc'].idxmax()  # æœ€ä½³æ·±åº¦ç´¢å¼•
best_depth = cv_df.loc[best_idx, 'depth']

# 4. å¯è§†åŒ–ï¼šæ·±åº¦-å‡†ç¡®ç‡å…³ç³»ï¼ˆå«è¯¯å·®æ¡+å¶èŠ‚ç‚¹æ ‡æ³¨ï¼‰
plt.figure(figsize=(19, 8))

# ä¸»å›¾ï¼šå‡†ç¡®ç‡æŠ˜çº¿ï¼ˆå¸¦è¯¯å·®æ¡ï¼‰
plt.errorbar(
    x=cv_df['depth'],
    y=cv_df['mean_acc'],
    yerr=cv_df['std_acc'],
    fmt='o-',
    color='#2E86C1',
    ecolor='#3498DB',
    elinewidth=2,
    capsize=8,
    label=f'åæŠ˜å¹³å‡å‡†ç¡®ç‡ï¼ˆÂ±æ ‡å‡†å·®ï¼‰'
)

# æ¬¡è½´ï¼šå¶èŠ‚ç‚¹æ•°ï¼ˆå³ä¾§Yè½´ï¼‰
ax2 = plt.twinx()
ax2.plot(
    cv_df['depth'],
    cv_df['leaves'],
    's--',
    color='#E74C3C',
    label='å¶èŠ‚ç‚¹æ•°é‡'
)
ax2.set_ylabel('å¶èŠ‚ç‚¹æ•°é‡', color='#E74C3C', fontsize=12)
ax2.tick_params(axis='y', labelcolor='#E74C3C')

# æ ‡æ³¨æœ€ä½³æ·±åº¦
best_row = cv_df.iloc[best_idx]
plt.scatter(
    best_depth, best_row['mean_acc'],
    s=200, color='green', marker='*',
    edgecolors='white', linewidth=2,
)

# å›¾è¡¨ç¾åŒ–
plt.title("å‰ªææ·±åº¦å¯¹å‡†ç¡®ç‡çš„å½±å“ï¼ˆåæŠ˜äº¤å‰éªŒè¯ï¼‰", fontsize=16, pad=25)
plt.xlabel("å†³ç­–æ ‘æ·±åº¦ï¼ˆå‰ªæç¨‹åº¦ï¼‰", fontsize=13)
plt.ylabel("å¹³å‡å‡†ç¡®ç‡", color='#2E86C1', fontsize=13)
plt.xticks(depths, labels=[f'D{i}' for i in depths])
plt.grid(True, linestyle='--', alpha=0.6, which='both')
plt.legend(bbox_to_anchor=(1, 1), loc='upper left', fontsize=11)
plt.show()