import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import time
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split, cross_val_score
from fuzzytree import FuzzyDecisionTreeClassifier
from deap import base, creator, tools, algorithms
import random

# è®¾ç½®å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# è¯»å–æ•°æ®
df = pd.read_csv("student-por.csv", sep=';',
                 usecols=['failures', 'studytime', 'absences', 'age', 'Walc', 'famrel', 'G3'])
df = df.dropna().reset_index(drop=True)
df['G3_bin'] = (df['G3'] >= 10).astype(int)

X = df[['failures', 'studytime', 'absences', 'age', 'Walc', 'famrel']].values
y = df['G3_bin'].values

feature_num = X.shape[1]


# === åˆ†ä½æ•°æ–¹æ³•æ„å»ºæ¨¡ç³Šå‡½æ•°å‚æ•° ===
def quantile_fuzzify_params(X):
    params = []
    for col in X.T:
        q25, q50, q75 = np.percentile(col, [25, 50, 75])
        xmin, xmax = np.min(col), np.max(col)
        # 3 ä¸ªæ¨¡ç³Šé›†ï¼Œæ¯ä¸ªæ˜¯ a, b, c
        F_low = (xmin, q25, (q25 + q50) / 2)
        F_mid = ((q25 + q50) / 2, q50, (q50 + q75) / 2)
        F_high = ((q50 + q75) / 2, q75, xmax)
        params.extend([F_low, F_mid, F_high])
    return np.array(params).reshape(feature_num, 3, 3)


# === æ¨¡ç³ŠåŒ–æ•°æ® ===
def fuzzify_data(X, fuzzy_params):
    n_samples, n_features = X.shape
    result = []
    for i in range(n_features):
        params = fuzzy_params[i]
        col = X[:, i]
        col_fuzz = []
        for (a, b, c) in params:
            Î¼ = np.where(
                col <= a, 0,
                np.where(col <= b, (col - a) / (b - a + 1e-6),
                         np.where(col <= c, (c - col) / (c - b + 1e-6), 0))
            )
            col_fuzz.append(Î¼)
        result.extend(col_fuzz)
    return np.vstack(result).T  # shape (n_samples, n_features * 3)


# === æ–¹æ³•1ï¼šåˆ†ä½æ•°æ–¹æ³• ===
start_time = time.time()
quantile_params = quantile_fuzzify_params(X)
X_quantile_fuzzified = fuzzify_data(X, quantile_params)

X_train, X_test, y_train, y_test = train_test_split(X_quantile_fuzzified, y, test_size=0.3, random_state=42)
model = FuzzyDecisionTreeClassifier(max_depth=3)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
acc_quantile = accuracy_score(y_test, y_pred)
time_quantile = time.time() - start_time


# === æ–¹æ³•2ï¼šé—ä¼ ç®—æ³• ===
# å†³ç­–æ ‘è®­ç»ƒå‡½æ•°
def evaluate_individual(individual):
    params = np.array(individual).reshape(feature_num, 3, 3)
    X_fuzz = fuzzify_data(X, params)
    scores = cross_val_score(FuzzyDecisionTreeClassifier(max_depth=3), X_fuzz, y, cv=5)
    return scores.mean(),


# è®¾ç½®é—ä¼ ç®—æ³•å‚æ•°
creator.create("FitnessMax", base.Fitness, weights=(1.0,))
creator.create("Individual", list, fitness=creator.FitnessMax)

toolbox = base.Toolbox()
# ç”Ÿæˆåˆå§‹ä¸ªä½“ï¼ˆæŒ‰ç‰¹å¾ min-max èŒƒå›´ï¼‰
param_bounds = []
for col in X.T:
    xmin, xmax = np.min(col), np.max(col)
    for _ in range(3):  # æ¯ä¸ªæ¨¡ç³Šé›†
        param_bounds.extend([(xmin, xmax)] * 3)


def uniform_param(low, high):
    return random.uniform(low, high)


toolbox.register("attr_float", lambda: uniform_param(*random.choice(param_bounds)))
toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_float, n=feature_num * 3 * 3)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

toolbox.register("evaluate", evaluate_individual)
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=0.5, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)

random.seed(42)

start_time = time.time()

pop = toolbox.population(n=100)
hof = tools.HallOfFame(1)
stats = tools.Statistics(lambda ind: ind.fitness.values)
stats.register("avg", np.mean)
stats.register("max", np.max)

pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.7, mutpb=0.2, ngen=50,
                               stats=stats, halloffame=hof, verbose=False)

best_params = np.array(hof[0]).reshape(feature_num, 3, 3)
X_genetic_fuzzified = fuzzify_data(X, best_params)

X_train, X_test, y_train, y_test = train_test_split(X_genetic_fuzzified, y, test_size=0.3, random_state=42)
model = FuzzyDecisionTreeClassifier(max_depth=3)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
acc_genetic = accuracy_score(y_test, y_pred)
time_genetic = time.time() - start_time

# === è¾“å‡ºå¯¹æ¯”ç»“æœ ===
print(f"âœ… åˆ†ä½æ•°æ–¹æ³•å‡†ç¡®ç‡: {acc_quantile:.4f}ï¼Œè€—æ—¶: {time_quantile:.2f} ç§’")
print(f"ğŸ§¬ é—ä¼ ç®—æ³•æ–¹æ³•å‡†ç¡®ç‡: {acc_genetic:.4f}ï¼Œè€—æ—¶: {time_genetic:.2f} ç§’")

# === å‡†ç¡®ç‡ & æ—¶é—´ å¯¹æ¯”å›¾ ===
labels = ['åˆ†ä½æ•°æ–¹æ³•', 'é—ä¼ ç®—æ³•']
accuracies = [acc_quantile, acc_genetic]
times = [time_quantile, time_genetic]

fig, ax1 = plt.subplots(figsize=(8, 5))

bar_width = 0.35
x = np.arange(len(labels))

# å·¦è½´ï¼šå‡†ç¡®ç‡
ax1.bar(x - bar_width / 2, accuracies, bar_width, label='å‡†ç¡®ç‡', color='skyblue')
ax1.set_ylabel('å‡†ç¡®ç‡')
ax1.set_ylim(0, 1)

# å³è½´ï¼šè€—æ—¶
ax2 = ax1.twinx()
ax2.bar(x + bar_width / 2, times, bar_width, label='è€—æ—¶ (ç§’)', color='salmon')
ax2.set_ylabel('è€—æ—¶ (ç§’)')

# Xè½´æ ‡ç­¾
ax1.set_xticks(x)
ax1.set_xticklabels(labels)

# å›¾ä¾‹
fig.legend(loc='upper right', bbox_to_anchor=(1, 1), bbox_transform=ax1.transAxes)

plt.title("åˆ†ä½æ•°æ–¹æ³• vs é—ä¼ ç®—æ³•ï¼šå‡†ç¡®ç‡ & è€—æ—¶å¯¹æ¯”")
plt.tight_layout()
plt.show()

# === ç»˜åˆ¶é—ä¼ ç®—æ³•æ¯ä¸€ä»£çš„å¹³å‡å‡†ç¡®ç‡æŠ˜çº¿å›¾ ===
gen = log.select("gen")
avg_accuracies = log.select("avg")

plt.figure(figsize=(8, 5))
plt.plot(gen, avg_accuracies, marker='o', linestyle='-', color='blue')
plt.title("é—ä¼ ç®—æ³•æ¯ä¸€ä»£çš„å¹³å‡å‡†ç¡®ç‡")
plt.xlabel("è¿­ä»£æ¬¡æ•°")
plt.ylabel("å¹³å‡å‡†ç¡®ç‡")
plt.grid(False)
plt.show()