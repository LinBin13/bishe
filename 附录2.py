import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, export_text, export_graphviz

# 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
try:
    df = pd.read_csv('student-por.csv', sep=';')
except FileNotFoundError:
    print("âŒ é”™è¯¯ï¼šè¯·å°†student-por.csvæ”¾åœ¨å½“å‰ç›®å½•")
    print("ğŸ“Œ ä¸‹è½½åœ°å€ï¼šhttps://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip")
    exit()

# æ•°æ®æ¸…æ´—ä¸ç‰¹å¾å·¥ç¨‹
df['G3_class'] = (df['G3'] >= 10).astype(int)
selected_features = ['failures', 'studytime', 'absences', 'age', 'Walc', 'famrel']
df = df[selected_features + ['G3_class']].dropna()

# åˆ†å‰²æ•°æ®é›†
X, y = df[selected_features], df['G3_class']
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,          # 20%ä½œä¸ºæµ‹è¯•é›†
    random_state=42,         # å›ºå®šéšæœºç§å­
    stratify=y               # ä¿æŒç±»åˆ«åˆ†å¸ƒ
)

# 2. è®­ç»ƒæœ€ä½³æ·±åº¦æ¨¡å‹
best_depth = 4  # å·²çŸ¥æœ€ä½³æ·±åº¦
model = DecisionTreeClassifier(
    max_depth=best_depth,
    min_samples_leaf=10,
    random_state=42
)
model.fit(X_train, y_train)

# 3. é¢„æµ‹å¹¶å±•ç¤ºç»“æœ
y_pred = model.predict(X_test)

# é€‰æ‹©å‰10ä¸ªæµ‹è¯•æ ·æœ¬å±•ç¤º
test_samples = X_test.head(10).copy()
test_samples['é¢„æµ‹ç»“æœ'] = y_pred[:10]
test_samples['çœŸå®ç»“æœ'] = y_test.head(10).values

print("\n==================== æµ‹è¯•æ ·æœ¬ç»“æœå±•ç¤º ====================")
print(test_samples[['failures', 'studytime', 'absences', 'age', 'Walc', 'famrel', 'é¢„æµ‹ç»“æœ', 'çœŸå®ç»“æœ']])
